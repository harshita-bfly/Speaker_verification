# Speaker Verification 


# Overview

Speaker verification utilizes speech characteristics to validate the speakerâ€™s identity. It has become increasingly important in security, where it is employed in several applications, including access control, monetary transactions, and safe communication, to authenticate people. This project focuses on verifying the speakers based on their voices. The speakers are the voices of famous virtual assistants:  Siri, Cortana, Google Assistant, and Alexa. Text-To-Speech (TTS) technology is often used to create these virtual assistants' voices. As a result, these assistants lack the natural variances in human voices. This project applies transfer learning to the ECAPA-TDNN (SoTA model for speech verification tasks) from the SpeechBrain toolkit, recognizing synthetic sounds and verifying the speakers. Inter and intra-comparisons are done on text-dependent and independent methods, and results are obtained based on evaluation metrics: accuracy, precision, recall, and F1 score.

A glimpse of the observation can be visualized:

![image](https://github.com/harshita-bfly/Speaker_verification/assets/100403649/92bf2523-8384-4d1e-9d52-488f9237573f)














